#!/usr/bin/env python3
"""
é™æ€æ•°æ®å­—æ®µä¾èµ–åˆ†æå·¥å…·
ç”¨äºåœ¨å¼€å‘é˜¶æ®µæ£€æŸ¥å­—æ®µä¾èµ–å…³ç³»å’Œæ½œåœ¨é—®é¢˜
"""

import os
import re
import ast
from typing import Dict, List, Set, Tuple, Optional, Any
from dataclasses import dataclass
from pathlib import Path

@dataclass
class FieldReference:
    """å­—æ®µå¼•ç”¨ä¿¡æ¯"""
    field_name: str
    file_path: str
    line_number: int
    context: str
    reference_type: str  # 'status_access', 'template_usage', 'definition'

@dataclass
class FieldDependency:
    """å­—æ®µä¾èµ–å…³ç³»"""
    source_field: str
    source_file: str
    target_fields: List[str]
    target_files: List[str]
    dependency_type: str

class StaticFieldAnalyzer:
    """é™æ€å­—æ®µåˆ†æå™¨"""

    def __init__(self, project_root: str):
        self.project_root = project_root
        self.field_references: List[FieldReference] = []
        self.dependencies: List[FieldDependency] = []

    def find_python_files(self) -> List[str]:
        """æŸ¥æ‰¾æ‰€æœ‰Pythonæ–‡ä»¶"""
        python_files = []
        for root, dirs, files in os.walk(self.project_root):
            # è·³è¿‡æµ‹è¯•ç›®å½•å’Œ__pycache__
            dirs[:] = [d for d in dirs if not d.startswith('__') and d != 'tests']

            for file in files:
                if file.endswith('.py'):
                    python_files.append(os.path.join(root, file))

        return python_files

    def analyze_file(self, file_path: str) -> List[FieldReference]:
        """åˆ†æå•ä¸ªæ–‡ä»¶çš„å­—æ®µå¼•ç”¨"""
        references = []

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                lines = content.split('\n')

            # 1. æŸ¥æ‰¾status[...]è®¿é—®æ¨¡å¼
            status_pattern = r'status\[(["\'])(\w+)\1\]'
            for line_num, line in enumerate(lines, 1):
                matches = re.finditer(status_pattern, line)
                for match in matches:
                    field_name = match.group(2)
                    references.append(FieldReference(
                        field_name=field_name,
                        file_path=file_path,
                        line_number=line_num,
                        context=line.strip(),
                        reference_type='status_access'
                    ))

            # 2. æŸ¥æ‰¾æ¨¡æ¿å­—ç¬¦ä¸²ä¸­çš„å­—æ®µä½¿ç”¨
            template_patterns = [
                r'\{(\w+)\}',  # ç®€å•å­—æ®µ
                r'\{(\w+)\:[^}]*\}',  # å¸¦æ ¼å¼çš„å­—æ®µ
            ]

            for line_num, line in enumerate(lines, 1):
                if 'template' in line.lower() or 'format' in line.lower():
                    for pattern in template_patterns:
                        matches = re.finditer(pattern, line)
                        for match in matches:
                            field_name = match.group(1)
                            if field_name.isalpha():  # ç¡®ä¿æ˜¯çº¯å­—æ®µå
                                references.append(FieldReference(
                                    field_name=field_name,
                                    file_path=file_path,
                                    line_number=line_num,
                                    context=line.strip(),
                                    reference_type='template_usage'
                                ))

            # 3. æŸ¥æ‰¾å­—æ®µå®šä¹‰ï¼ˆåœ¨returnè¯­å¥ä¸­ï¼‰
            for line_num, line in enumerate(lines, 1):
                if '"\\w+"\\s*:' in line or (line.strip().startswith('"') and ':' in line):
                    # ç®€å•çš„å­—æ®µå®šä¹‰æ£€æµ‹
                    field_def_pattern = r'"(\w+)"\s*:'
                    matches = re.finditer(field_def_pattern, line)
                    for match in matches:
                        field_name = match.group(1)
                        references.append(FieldReference(
                            field_name=field_name,
                            file_path=file_path,
                            line_number=line_num,
                            context=line.strip(),
                            reference_type='definition'
                        ))

        except Exception as e:
            print(f"åˆ†ææ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")

        return references

    def analyze_all_files(self) -> Dict[str, List[FieldReference]]:
        """åˆ†ææ‰€æœ‰æ–‡ä»¶çš„å­—æ®µå¼•ç”¨"""
        all_references = {}
        python_files = self.find_python_files()

        print(f"ğŸ” åˆ†æ {len(python_files)} ä¸ªPythonæ–‡ä»¶...")

        for file_path in python_files:
            relative_path = os.path.relpath(file_path, self.project_root)
            references = self.analyze_file(file_path)
            if references:
                all_references[relative_path] = references
                self.field_references.extend(references)

        return all_references

    def find_field_dependencies(self) -> List[FieldDependency]:
        """æŸ¥æ‰¾å­—æ®µä¾èµ–å…³ç³»"""
        dependencies = []

        # æŒ‰å­—æ®µååˆ†ç»„å¼•ç”¨
        field_groups: Dict[str, List[FieldReference]] = {}
        for ref in self.field_references:
            if ref.field_name not in field_groups:
                field_groups[ref.field_name] = []
            field_groups[ref.field_name].append(ref)

        # åˆ†ææ¯ä¸ªå­—æ®µçš„ä¾èµ–å…³ç³»
        for field_name, refs in field_groups.items():
            # æŸ¥æ‰¾å®šä¹‰å’Œè®¿é—®
            definitions = [r for r in refs if r.reference_type == 'definition']
            accesses = [r for r in refs if r.reference_type in ['status_access', 'template_usage']]

            if definitions and accesses:
                # åˆ›å»ºä»å®šä¹‰åˆ°è®¿é—®çš„ä¾èµ–
                for def_ref in definitions:
                    target_fields = []
                    target_files = []

                    for access_ref in accesses:
                        if access_ref.file_path != def_ref.file_path:
                            target_fields.append(access_ref.field_name)
                            target_files.append(access_ref.file_path)

                    if target_fields:
                        dependencies.append(FieldDependency(
                            source_field=field_name,
                            source_file=def_ref.file_path,
                            target_fields=list(set(target_fields)),
                            target_files=list(set(target_files)),
                            dependency_type='definition_to_usage'
                        ))

        return dependencies

    def detect_potential_issues(self) -> List[str]:
        """æ£€æµ‹æ½œåœ¨é—®é¢˜"""
        issues = []

        # æŒ‰å­—æ®µååˆ†ç»„
        field_groups: Dict[str, List[FieldReference]] = {}
        for ref in self.field_references:
            if ref.field_name not in field_groups:
                field_groups[ref.field_name] = []
            field_groups[ref.field_name].append(ref)

        # æ£€æŸ¥1: åªæœ‰è®¿é—®æ²¡æœ‰å®šä¹‰çš„å­—æ®µ
        print("\nğŸ” æ£€æŸ¥å­—æ®µå®šä¹‰å®Œæ•´æ€§...")
        for field_name, refs in field_groups.items():
            definitions = [r for r in refs if r.reference_type == 'definition']
            accesses = [r for r in refs if r.reference_type in ['status_access', 'template_usage']]

            if accesses and not definitions:
                files_using = set(r.file_path for r in accesses)
                issues.append(f"âš ï¸  å­—æ®µ '{field_name}' è¢«è®¿é—®ä½†æœªå®šä¹‰ (ä½¿ç”¨äº: {', '.join(files_using)})")

        # æ£€æŸ¥2: å¯èƒ½çš„æ‹¼å†™é”™è¯¯
        print("\nğŸ” æ£€æŸ¥å¯èƒ½çš„æ‹¼å†™é”™è¯¯...")
        common_fields = {'name', 'hp', 'mp', 'exp', 'realm', 'talent', 'pills', 'level', 'power'}
        for field_name in field_groups.keys():
            if field_name not in common_fields:
                # æ£€æŸ¥æ˜¯å¦æ˜¯å¸¸è§å­—æ®µçš„æ‹¼å†™é”™è¯¯
                for common_field in common_fields:
                    if self._is_similar(field_name, common_field):
                        issues.append(f"ğŸ” å¯èƒ½çš„æ‹¼å†™é”™è¯¯: '{field_name}' (åº”ä¸º '{common_field}'?)")

        # æ£€æŸ¥3: ç‰¹æ®Šæ¨¡å¼æ£€æŸ¥
        print("\nğŸ” æ£€æŸ¥ç‰¹æ®Šæ¨¡å¼...")

        # æ£€æŸ¥exp_thresholdç›¸å…³ï¼ˆæˆ‘ä»¬å·²çŸ¥çš„é—®é¢˜ï¼‰
        exp_threshold_refs = field_groups.get('exp_threshold', [])
        if exp_threshold_refs:
            exp_progress_refs = field_groups.get('exp_progress', [])
            if exp_progress_refs:
                issues.append(f"ğŸ¯ å‘ç°exp_thresholdä½¿ç”¨ (å·²åœ¨ä¿®å¤ä¸­): {len(exp_threshold_refs)}å¤„å¼•ç”¨")

        return issues

    def analyze_action_contract_consistency(self) -> Dict[str, Any]:
        """åˆ†æåŠ¨ä½œå¥‘çº¦ä¸€è‡´æ€§"""
        print("\nğŸ” åˆ†æåŠ¨ä½œå¥‘çº¦ä¸€è‡´æ€§...")

        try:
            from actions import ActionFactory
            from ui.layouts import default_layout
            from ui.pygame_renderer import PygameInputHandler

            # è·å–åç«¯å®šä¹‰çš„åŠ¨ä½œ
            backend_actions = {}
            for action in ActionFactory.get_all_actions():
                backend_actions[action.name] = {
                    'class_name': action.__class__.__name__,
                    'description': action.description,
                    'file_path': 'actions.py'
                }

            # è·å–UIå±‚å®šä¹‰çš„åŠ¨ä½œ
            ui_actions = {}
            for button in default_layout.ACTION_BUTTONS:
                action_name = button["action"]
                if action_name in backend_actions:  # åªå…³æ³¨æ¸¸æˆåŠ¨ä½œ
                    ui_actions[action_name] = {
                        'display_name': button["name"],
                        'description': button["description"],
                        'file_path': 'ui/layouts.py'
                    }

            # è·å–å¿«æ·é”®æ˜ å°„
            renderer = PygameInputHandler(default_layout)
            shortcut_actions = {}
            for key_code, action_name in renderer.shortcuts.items():
                if action_name in backend_actions:  # åªå…³æ³¨æ¸¸æˆåŠ¨ä½œ
                    shortcut_actions[action_name] = {
                        'key_code': key_code,
                        'key_name': f"pygame.K_{key_code}",
                        'file_path': 'ui/pygame_renderer.py'
                    }

            # æ£€æŸ¥ä¸€è‡´æ€§
            consistency_results = {
                'backend_actions': backend_actions,
                'ui_actions': ui_actions,
                'shortcut_actions': shortcut_actions,
                'issues': [],
                'missing_in_ui': [],
                'missing_in_backend': [],
                'missing_shortcuts': []
            }

            # æ£€æŸ¥åç«¯åŠ¨ä½œåœ¨UIå±‚æ˜¯å¦å­˜åœ¨
            for action_name in backend_actions.keys():
                if action_name not in ui_actions:
                    consistency_results['missing_in_ui'].append(action_name)
                    consistency_results['issues'].append(f"âš ï¸  åç«¯åŠ¨ä½œ '{action_name}' åœ¨UIå±‚æ²¡æœ‰å¯¹åº”çš„æŒ‰é’®")

                if action_name not in shortcut_actions:
                    consistency_results['missing_shortcuts'].append(action_name)
                    consistency_results['issues'].append(f"âš ï¸  åç«¯åŠ¨ä½œ '{action_name}' æ²¡æœ‰å¯¹åº”çš„å¿«æ·é”®")

            # æ£€æŸ¥UIå±‚åŠ¨ä½œåœ¨åç«¯æ˜¯å¦å­˜åœ¨
            for action_name in ui_actions.keys():
                if action_name not in backend_actions:
                    consistency_results['missing_in_backend'].append(action_name)
                    consistency_results['issues'].append(f"âš ï¸  UIåŠ¨ä½œ '{action_name}' åœ¨åç«¯æ²¡æœ‰å¯¹åº”çš„å®ç°")

            return consistency_results

        except Exception as e:
            print(f"åˆ†æåŠ¨ä½œå¥‘çº¦æ—¶å‡ºé”™: {e}")
            return {
                'backend_actions': {},
                'ui_actions': {},
                'shortcut_actions': {},
                'issues': [f"åˆ†æåŠ¨ä½œå¥‘çº¦æ—¶å‡ºé”™: {e}"],
                'missing_in_ui': [],
                'missing_in_backend': [],
                'missing_shortcuts': []
            }

    def find_hardcoded_action_strings(self) -> List[Dict[str, Any]]:
        """æŸ¥æ‰¾ç¡¬ç¼–ç çš„åŠ¨ä½œå­—ç¬¦ä¸²"""
        print("\nğŸ” æŸ¥æ‰¾ç¡¬ç¼–ç çš„åŠ¨ä½œå­—ç¬¦ä¸²...")

        hardcoded_strings = []
        action_names = {'meditate', 'consume_pill', 'cultivate', 'wait'}

        for ref in self.field_references:
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç¡¬ç¼–ç çš„åŠ¨ä½œåç§°
            if (ref.field_name in action_names or
                ref.reference_type in ['status_access', 'template_usage']):

                # æ£€æŸ¥ä¸Šä¸‹æ–‡æ˜¯å¦åŒ…å«åŠ¨ä½œåç§°
                context_lower = ref.context.lower()
                for action_name in action_names:
                    if action_name in context_lower:
                        hardcoded_strings.append({
                            'action_name': action_name,
                            'file_path': ref.file_path,
                            'line_number': ref.line_number,
                            'context': ref.context,
                            'reference_type': ref.reference_type
                        })
                        break

        return hardcoded_strings

    def _is_similar(self, str1: str, str2: str) -> bool:
        """æ£€æŸ¥ä¸¤ä¸ªå­—ç¬¦ä¸²æ˜¯å¦ç›¸ä¼¼ï¼ˆæ‹¼å†™é”™è¯¯æ£€æµ‹ï¼‰"""
        # ç®€å•çš„ç¼–è¾‘è·ç¦»æ£€æµ‹
        if abs(len(str1) - len(str2)) > 2:
            return False

        common_chars = set(str1) & set(str2)
        similarity = len(common_chars) / max(len(set(str1)), len(set(str2)))
        return similarity > 0.7

    def generate_analysis_report(self) -> str:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        report = []
        report.append("=" * 80)
        report.append("ğŸ”¬ é™æ€å­—æ®µä¾èµ–åˆ†ææŠ¥å‘Š")
        report.append("=" * 80)
        report.append(f"ğŸ“ é¡¹ç›®è·¯å¾„: {self.project_root}")
        report.append(f"ğŸ“„ åˆ†ææ–‡ä»¶æ•°: {len(set(r.file_path for r in self.field_references))}")
        report.append(f"ğŸ”¤ å‘ç°å­—æ®µæ•°: {len(set(r.field_name for r in self.field_references))}")
        report.append(f"ğŸ“ æ€»å¼•ç”¨æ•°: {len(self.field_references)}")
        report.append("")

        # å­—æ®µä½¿ç”¨ç»Ÿè®¡
        field_counts: Dict[str, int] = {}
        for ref in self.field_references:
            field_counts[ref.field_name] = field_counts.get(ref.field_name, 0) + 1

        report.append("ğŸ“Š å­—æ®µä½¿ç”¨é¢‘ç‡ TOP 10:")
        sorted_fields = sorted(field_counts.items(), key=lambda x: x[1], reverse=True)[:10]
        for field_name, count in sorted_fields:
            report.append(f"   {field_name}: {count} æ¬¡")
        report.append("")

        # ä¾èµ–å…³ç³»
        dependencies = self.find_field_dependencies()
        report.append(f"ğŸ”— å‘ç° {len(dependencies)} ä¸ªå­—æ®µä¾èµ–å…³ç³»:")
        for dep in dependencies[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
            report.append(f"   {dep.source_field} ({os.path.basename(dep.source_file)}) â†’ {', '.join(dep.target_files)}")
        report.append("")

        # åŠ¨ä½œå¥‘çº¦ä¸€è‡´æ€§åˆ†æ
        action_analysis = self.analyze_action_contract_consistency()
        report.append("ğŸ® åŠ¨ä½œå¥‘çº¦ä¸€è‡´æ€§åˆ†æ:")
        report.append(f"   åç«¯å®šä¹‰åŠ¨ä½œ: {len(action_analysis['backend_actions'])} ä¸ª")
        report.append(f"   UIå±‚æŒ‰é’®åŠ¨ä½œ: {len(action_analysis['ui_actions'])} ä¸ª")
        report.append(f"   å¿«æ·é”®æ˜ å°„åŠ¨ä½œ: {len(action_analysis['shortcut_actions'])} ä¸ª")

        if action_analysis['issues']:
            report.append("")
            report.append("âš ï¸  åŠ¨ä½œå¥‘çº¦é—®é¢˜:")
            for issue in action_analysis['issues']:
                report.append(f"   {issue}")
        else:
            report.append("âœ… åŠ¨ä½œå¥‘çº¦å®Œå…¨ä¸€è‡´")

        # ç¡¬ç¼–ç åŠ¨ä½œå­—ç¬¦ä¸²
        hardcoded_actions = self.find_hardcoded_action_strings()
        if hardcoded_actions:
            report.append("")
            report.append(f"ğŸ” å‘ç° {len(hardcoded_actions)} å¤„ç¡¬ç¼–ç åŠ¨ä½œå­—ç¬¦ä¸²:")
            for i, action_str in enumerate(hardcoded_actions[:5]):  # æ˜¾ç¤ºå‰5ä¸ª
                report.append(f"   {action_str['action_name']} åœ¨ {action_str['file_path']}:{action_str['line_number']}")
        else:
            report.append("")
            report.append("âœ… æœªå‘ç°ç¡¬ç¼–ç åŠ¨ä½œå­—ç¬¦ä¸²é—®é¢˜")

        # å…¶ä»–æ½œåœ¨é—®é¢˜
        issues = self.detect_potential_issues()
        if issues:
            report.append("")
            report.append("âš ï¸  å…¶ä»–æ½œåœ¨é—®é¢˜:")
            for issue in issues:
                report.append(f"   {issue}")
        else:
            report.append("")
            report.append("âœ… æœªå‘ç°å…¶ä»–å­—æ®µä¾èµ–é—®é¢˜")

        report.append("")
        report.append("=" * 80)

        return "\n".join(report)

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¬ å¼€å§‹é™æ€å­—æ®µä¾èµ–åˆ†æ...")

    project_root = os.path.dirname(os.path.abspath(__file__))
    analyzer = StaticFieldAnalyzer(project_root)

    # åˆ†ææ‰€æœ‰æ–‡ä»¶
    all_references = analyzer.analyze_all_files()

    # ç”ŸæˆæŠ¥å‘Š
    report = analyzer.generate_analysis_report()
    print("\n" + report)

    # ä¿å­˜æŠ¥å‘Š
    report_path = os.path.join(project_root, 'field_dependency_report.txt')
    try:
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)
        print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
    except Exception as e:
        print(f"ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")

if __name__ == "__main__":
    main()